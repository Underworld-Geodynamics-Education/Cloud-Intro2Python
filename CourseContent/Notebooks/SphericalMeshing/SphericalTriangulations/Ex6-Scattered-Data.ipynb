{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 6 - Scattered Data and 'Heat Maps'\n",
    "\n",
    "There are different ways to map point data to a smooth field. One way is to triangulate the data, smooth it and interpolate to a regular mesh (see previous notebooks). It is also possible to construct weighted averages from scattered points to a regular mesh. In this notebook we work through how to find where points lie in the mesh and map their values to nearby vertices. \n",
    "\n",
    "#### Notebook contents\n",
    "\n",
    "   - [Computational mesh](#Define-a-regular-computational-mesh)\n",
    "   - [Scattered data](#Point-data-with-uneven-spatial-distribution)\n",
    "   - [Data count by triangle](#Count-earthquakes-per-triangle)\n",
    "   - [Data count by nearest vertex](#Count-earthquakes-per-vertex)\n",
    "   - [Distance weighting to vertices](#Inverse-distance-weighted-number-of-earthquakes)\n",
    "   - [Visualisation](#Visualisation)\n",
    "   \n",
    "   \n",
    "The next example is [Ex7-Refinement-of-Triangulations](./Ex7-Refinement-of-Triangulations.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a regular computational mesh\n",
    "\n",
    "Use the (usual) icosahedron with face points included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py27/lib/python2.7/site-packages/scipy/sparse/lil.py:19: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _csparsetools\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:165: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\\\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:167: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._traversal import breadth_first_order, depth_first_order, \\\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:169: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._min_spanning_tree import minimum_spanning_tree\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:170: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._reordering import reverse_cuthill_mckee, maximum_bipartite_matching, \\\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/scipy/spatial/__init__.py:95: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ckdtree import *\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/scipy/spatial/__init__.py:96: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .qhull import *\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/scipy/spatial/_spherical_voronoi.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _voronoi\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/scipy/spatial/distance.py:122: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hausdorff\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/scipy/linalg/basic.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._solve_toeplitz import levinson\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/scipy/linalg/__init__.py:207: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._decomp_update import *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30722\n"
     ]
    }
   ],
   "source": [
    "import stripy as stripy\n",
    "\n",
    "mesh = stripy.spherical_meshes.icosahedral_mesh(refinement_levels=5, include_face_points=True, tree=True)\n",
    "\n",
    "print(mesh.npoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point data with uneven spatial distribution\n",
    "\n",
    "Define a relatively smooth function that we can interpolate from the coarse mesh to the fine mesh and analyse. As it is a familiar pattern, we use the seismic event catalogue for M5.5+ (dawn of time to 2017-12-31) from IRIS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Note - these data have some places where depth is unknown (appears as NaN in the depth )\n",
    "# The IRIS data has  lat, lon, depth, mag  ... date/time in col 2, 3, 4, 10 (starting from zero)\n",
    "\n",
    "eqs = np.genfromtxt(\"../Data/EQ-M5.5-IRIS-ALL.txt\", usecols=(2,3,4,10), delimiter='|', comments=\"#\")    \n",
    "        \n",
    "\n",
    "lons = np.radians(eqs[:,1])\n",
    "lats = np.radians(eqs[:,0])\n",
    "depths = eqs[:,2]\n",
    "depths[np.isnan(depths)] = -1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named cartopy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-28951ea6e38a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# import gdal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcartopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcartopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mccrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named cartopy"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import gdal\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5), facecolor=\"none\")\n",
    "ax  = plt.subplot(111, projection=ccrs.Mollweide())\n",
    "ax.coastlines(color=\"#777777\" )\n",
    "ax.set_global()\n",
    "\n",
    "lons0 = np.degrees(lons)\n",
    "lats0 = np.degrees(lats)\n",
    "\n",
    "ax.scatter(lons0, lats0, \n",
    "            marker=\"o\", s=10.0, alpha=0.5, \n",
    "            transform=ccrs.Geodetic(), c=depths, cmap=plt.cm.RdBu)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count earthquakes per triangle \n",
    "\n",
    "This is a numpy wrapper around the `STRIPACK` routine which operates by retriangulation and is therefore not particularly fast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangles = mesh.containing_triangle(lons, lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The return_counts argument is quite new in numpy\n",
    "\n",
    "try:\n",
    "    tris, counts = np.unique(triangles, return_counts=True)\n",
    "except:\n",
    "\n",
    "    def unique_count(a):\n",
    "        unique, inverse = np.unique(a, return_inverse=True)\n",
    "        count = np.zeros(len(unique), np.int)\n",
    "        np.add.at(count, inverse, 1)\n",
    "        return unique, count\n",
    "\n",
    "    tris, counts = unique_count(triangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3376,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42119653668380963\n"
     ]
    }
   ],
   "source": [
    "## map to nodes so we can plot this\n",
    "\n",
    "hit_count = np.zeros_like(mesh.lons)\n",
    "\n",
    "for i in range(0, tris.shape[0]):\n",
    "    hit_count[mesh.simplices[tris[i]]] += counts[i]\n",
    "\n",
    "hit_count /= 3.0\n",
    "\n",
    "print(hit_count.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-16256013403e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"none\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mccrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMollweide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoastlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lightgrey\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_global\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 10), facecolor=\"none\")\n",
    "ax  = plt.subplot(111, projection=ccrs.Mollweide())\n",
    "ax.coastlines(color=\"lightgrey\", )\n",
    "ax.set_global()\n",
    "\n",
    "lons0 = np.degrees(mesh.lons)\n",
    "lats0 = np.degrees(mesh.lats)\n",
    "\n",
    "ax.scatter(lons0, lats0, \n",
    "            marker=\"o\", s=30.0, transform=ccrs.Geodetic(), c=hit_count, cmap=plt.cm.Reds, vmin=0.333, vmax=20.0, alpha=0.25)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count earthquakes per vertex\n",
    "\n",
    "The `sTriangulation.nearest_vertices` method uses a k-d tree to find the nearest vertices to a set of longitude / latitude points. It returns the great circle distance. This requires the k-d tree to have been built when the mesh was initialised (`tree=True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, vertices = mesh.nearest_vertices(lons, lats, k=1)\n",
    "nodes, ncounts = np.unique(vertices, return_counts=True)\n",
    "\n",
    "hit_countn = np.zeros_like(mesh.lons)\n",
    "hit_countn[nodes] = ncounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10), facecolor=\"none\")\n",
    "ax  = plt.subplot(111, projection=ccrs.Mollweide())\n",
    "ax.coastlines(color=\"lightgrey\", )\n",
    "ax.set_global()\n",
    "\n",
    "lons0 = np.degrees(mesh.lons)\n",
    "lats0 = np.degrees(mesh.lats)\n",
    "\n",
    "ax.scatter(lons0, lats0, \n",
    "            marker=\"o\", s=30.0, transform=ccrs.Geodetic(), c=hit_countn, cmap=plt.cm.Reds, vmin=0.333, vmax=10.0, alpha=0.25)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse distance weighted number of earthquakes\n",
    "\n",
    "The k-d tree method provides a specified number of neighbours and the arc lengths to those neighbours. This can be used in a number of ways to smooth or amalgamate data. Here for example is a weighted average of each earthquake to nearby nodes. \n",
    "\n",
    "We compute the distances to $N$ nearby vertices and distribute information to those vertices in inverse proportion to their distance.\n",
    "\n",
    "$$ w _i = \\frac{d _i}{\\sum_{i=1}^N d _i} $$\n",
    "\n",
    "Alternatively, we might map information to the vertices by applying a radially symmetric kernel to the point data without normalising.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, vertices = mesh.nearest_vertices(lons, lats, k=10)\n",
    "norm = distances.sum(axis=1)\n",
    "\n",
    "# distances, vertices are arrays of shape (data_size, 10)\n",
    "\n",
    "hit_countid = np.zeros_like(mesh.lons)\n",
    "\n",
    "## numpy shouldn't try to vectorise this reduction operation\n",
    "\n",
    "for i in range(0,distances.shape[0]):\n",
    "    hit_countid[vertices[i,:]] += distances[i,:] / norm[i]\n",
    "\n",
    "\n",
    "hit_countidr = np.zeros_like(mesh.lons)\n",
    "\n",
    "## numpy shouldn't try to vectorise this reduction operation\n",
    "\n",
    "for i in range(0,distances.shape[0]):\n",
    "    hit_countidr[vertices[i,:]] += np.exp( -distances[i,:] / 0.02 ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10), facecolor=\"none\")\n",
    "ax  = plt.subplot(111, projection=ccrs.Mollweide())\n",
    "ax.coastlines(color=\"lightgrey\", )\n",
    "ax.set_global()\n",
    "\n",
    "lons0 = np.degrees(mesh.lons)\n",
    "lats0 = np.degrees(mesh.lats)\n",
    "\n",
    "ax.scatter(lons0, lats0, \n",
    "            marker=\"o\", s=30.0, transform=ccrs.Geodetic(), c=hit_countid, cmap=plt.cm.Reds, vmin=0.333, vmax=10.0, alpha=0.25)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping data other than frequency to the regular mesh\n",
    "\n",
    "Here we show how to map point data to the regular mesh - produce a representation of the depth of the events instead of just their frequency. When plotting, we need to distinguish between zero information and zero (shallow) depth. This is done by using the weight function to determine the opacity of the symbol or field that we plot. This has the effect of washing out the regions with few, large events compared to those with many small ones (which in this case means washed out regions where earthquakes are deep). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_idr = np.zeros_like(mesh.lons)\n",
    "\n",
    "## numpy shouldn't try to vectorise this reduction operation\n",
    "\n",
    "for i in range(0,distances.shape[0]):\n",
    "    depth_idr[vertices[i,:]] += depths[i] * np.exp( -distances[i,:] / 0.02 ) \n",
    "\n",
    "depth_idr[hit_countidr != 0.0] /=  hit_countidr[hit_countidr != 0.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10), facecolor=\"none\")\n",
    "ax  = plt.subplot(111, projection=ccrs.Mollweide())\n",
    "ax.coastlines(color=\"lightgrey\", )\n",
    "ax.set_global()\n",
    "\n",
    "lons0 = np.degrees(mesh.lons)\n",
    "lats0 = np.degrees(mesh.lats)\n",
    "\n",
    "ax.scatter(lons0, lats0, \n",
    "            marker=\"o\", transform=ccrs.Geodetic(), c=depth_idr, s=hit_countidr,\n",
    "            cmap=plt.cm.RdBu, vmin=0.0, vmax=500.0, alpha=0.25)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lavavu\n",
    "\n",
    "\n",
    "depth_range = depths.max()\n",
    "\n",
    "lv = lavavu.Viewer(border=False, background=\"#FFFFFF\", resolution=[666,666], near=-10.0)\n",
    "\n",
    "\n",
    "tris = lv.triangles(\"triangles\",  wireframe=False, colour=\"#77ff88\", opacity=1.0)\n",
    "tris.vertices(mesh.points)\n",
    "tris.indices(mesh.simplices)\n",
    "\n",
    "tris.values(hit_count, label=\"hit_count\")\n",
    "tris.values(hit_countn, label=\"hit_countn\")\n",
    "tris.values(hit_countid, label=\"hit_countid\")\n",
    "tris.values(hit_countidr, label=\"hit_countidr\")\n",
    "tris.colourmap(\"#FFFFFF:0.0 (1.0)#FF0000:0.2 (50.0)#550044:0.5\")\n",
    "\n",
    "\n",
    "depth = lv.triangles(\"depth_field\",  wireframe=False, colour=\"#FFFFFF\", opacity=0.999)\n",
    "depth.vertices(mesh.points*(6370-depth_range*0.99) / 6370)\n",
    "depth.indices(mesh.simplices)\n",
    "depth.values(depth_idr, label=\"depths\")\n",
    "depth.values(hit_countidr/hit_countidr.max(), label=\"weights\")\n",
    "depth.colourmap(\"#550000 #0099FF #000055\")\n",
    "\n",
    "depth[\"opacitymap\"] = \"#000000:0.0 (0.1)#000000:0.9 #000000:0.9\"\n",
    "depth[\"opacityby\"] = \"weights\"\n",
    "depth[\"colourby\"]  = \"depths\"\n",
    " \n",
    "bg = lv.triangles(\"background\",  wireframe=False, colour=\"#FFFFFF\", opacity=1.0)\n",
    "bg.vertices(mesh.points*(6370-depth_range) / 6370)\n",
    "bg.indices(mesh.simplices)\n",
    "\n",
    "ll = np.array(stripy.spherical.lonlat2xyz(lons, lats)).T\n",
    "\n",
    "nodes = lv.points(\"events\", pointsize=3.0, pointtype=\"shiny\", colour=\"#448080\", opacity=0.75)\n",
    "nodes.vertices(ll * (6370.0 - depths.reshape(-1,1)) / 6370.0 )\n",
    "nodes.values(depths, label=\"depths\")\n",
    "nodes.colourmap(\"#550000 #0099FF #000055\")\n",
    "\n",
    "# View from the pacific hemisphere \n",
    "lv.translation(0.0, 0.0, -3.0)\n",
    "lv.rotation(0.0,90.0, 90.0)\n",
    "\n",
    "\n",
    "lv.control.Panel()\n",
    "lv.control.Range('specular', range=(0,1), step=0.1, value=0.4)\n",
    "lv.control.Checkbox(property='axis')\n",
    "lv.control.ObjectList()\n",
    "tris.control.List([\"hit_count\", \"hit_countn\", \"hit_countid\", \"hit_countidr\"], property=\"colourby\", value=\"hit_count\", command=\"redraw\")\n",
    "lv.control.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next example is [Ex7-Refinement-of-Triangulations](./Ex7-Refinement-of-Triangulations.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
