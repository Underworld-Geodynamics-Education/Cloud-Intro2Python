{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "shown"
   },
   "source": [
    "### Datasets\n",
    "\n",
    "We need to download some data for the examples. Some files are bundled with the notebooks because I am not smart enough to understand how to download them through the various web / ftp interfaces directly or I needed to filter or compress the information for the purposes of the class. Please go to the original sites if you need to use these data for anything other than the demonstrations in these notebooks.\n",
    "\n",
    "Most datasets are too large for the repository (and generally, that's not a place to keep anything which is not the primary target of revision management. The bundled data are compressed and will be unpacked (copied) to the `../../Data/Resources` directory by the \"download\" functions in this notebook. If you mess them up, just run the download again. Anything that is undamaged will just be be skipped anyway.\n",
    "\n",
    "#### Global Magnetic Data\n",
    "\n",
    "Magnetic intensity data from [geomag.org](http://geomag.org/models/EMAG2/EMAG2_V2.tif)\n",
    "\n",
    "#### Topography data\n",
    "\n",
    "ETOPO1 images are from NOAA - we use their geotifs which are subsampled from the original (enormous) dataset but \n",
    "\n",
    "#### NASA Blue marble images\n",
    "\n",
    "Winter and Summer images for the Earth are grabbed for plotting examples. The winter ones (June) are used by default as these have less ice in the N. Hemisphere. \n",
    "\n",
    "#### Earthquake hypocentres\n",
    "\n",
    "Are grabbed from the [NEIC](http://earthquake.usgs.gov/earthquakes/search/) - they are in the geoJSON format since that is very simple to read with python. The downloads are limited at 20k events so the time and magnitude range is whatever it takes to get just under this limit. The filenames give clues about that, but, so does the catalogue itself once it is read in.\n",
    "\n",
    "#### Global age grid \n",
    "\n",
    "Taken from Earthbyte and reduced in size by throwing away the grid information and saving in compressed numpy format. \n",
    "\n",
    "#### Global strain rate\n",
    "\n",
    "I grabbed the second invariant of the strain rate from the [global strain rate map](http://gsrm.unavco.org/intro) project through the 'Jules Vernes' portal. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 145296\n",
      "-rw-r--r--  1 lmoresi  staff   4895422  9 Mar  2017 AusMagAll.tiff.zip\n",
      "-rw-r--r--  1 lmoresi  staff   5449584  9 Mar  2017 Earthquake_data.zip\n",
      "-rw-r--r--  1 lmoresi  staff    675266  9 Mar  2017 OrthographicProjectionBlueMarble.png\n",
      "-rw-r--r--  1 lmoresi  staff       214  9 Mar  2017 README.md\n",
      "-rw-r--r--@ 1 lmoresi  staff  33316312 14 Sep  2015 global_age_data.3.6.xyz.zip\n",
      "-rw-r--r--  1 lmoresi  staff  21987373  9 Mar  2017 global_age_data.3.6.z.npz\n",
      "-rwxr-xr-x  1 lmoresi  staff      2183  9 Mar  2017 nb_stripper.py\n",
      "-rw-r--r--  1 lmoresi  staff   4309416  9 Mar  2017 sec_invariant_strain_0.2.dat.zip\n",
      "-rw-r--r--  1 lmoresi  staff    466364  9 Mar  2017 velocity_AU.nc\n",
      "-rw-r--r--  1 lmoresi  staff    466364  9 Mar  2017 velocity_EU.nc\n",
      "-rw-r--r--  1 lmoresi  staff    466364  9 Mar  2017 velocity_IN.nc\n",
      "-rw-r--r--  1 lmoresi  staff    466364  9 Mar  2017 velocity_NA.nc\n",
      "-rw-r--r--  1 lmoresi  staff    466364  9 Mar  2017 velocity_NNR.nc\n",
      "-rw-r--r--  1 lmoresi  staff    466364  9 Mar  2017 velocity_OK.nc\n",
      "-rw-r--r--  1 lmoresi  staff    466324  9 Mar  2017 velocity_PA.nc\n",
      "-rw-r--r--  1 lmoresi  staff    466364  9 Mar  2017 velocity_TA.nc\n",
      "total 3500824\n",
      "-rw-r--r--  1 lmoresi  staff   97372378 29 Mar  2017 AusMagAll.tiff\n",
      "-rw-r--r--  1 lmoresi  staff    4895422 29 Mar  2017 AusMagAll.tiff.zip\n",
      "-rw-r--r--  1 lmoresi  staff   10714734 29 Mar  2017 BlueMarbleNG-TB_2004-06-01_rgb_3600x1800.TIFF\n",
      "-rw-r--r--  1 lmoresi  staff   10854863 29 Mar  2017 BlueMarbleNG-TB_2004-12-01_rgb_3600x1800.TIFF\n",
      "-rw-r--r--  1 lmoresi  staff  134722670 29 Mar  2017 EMAG2_image_V2.tif\n",
      "-rw-r--r--  1 lmoresi  staff  466647468 29 Mar  2017 ETOPO1_Ice_c_geotiff.tif\n",
      "-rw-r--r--  1 lmoresi  staff  323509293 29 Mar  2017 ETOPO_c_geotiff_10800.tif.zip\n",
      "-rw-r--r--  1 lmoresi  staff    5449584 29 Mar  2017 Earthquake_data.zip\n",
      "-rw-r--r--  1 lmoresi  staff    6145753 29 Mar  2017 Earthquakes-2000-2014-5.5+.json\n",
      "-rw-r--r--  1 lmoresi  staff   12090635 29 Mar  2017 Earthquakes-AusRegion-2000-2014-4.8-5.5+.json\n",
      "-rw-r--r--  1 lmoresi  staff    7961300 29 Mar  2017 Earthquakes-IBMRegion-1990-2014-3+.json\n",
      "-rw-r--r--  1 lmoresi  staff   10847985 29 Mar  2017 Earthquakes-JapanRegion-2009-2014-4.5+.json\n",
      "-rw-r--r--  1 lmoresi  staff   10976318 29 Mar  2017 Earthquakes-MeditRegion-1990-2014-3+.json\n",
      "-rw-r--r--  1 lmoresi  staff   11215875 29 Mar  2017 Earthquakes-YakutatRegion-1990-2014-3+.json\n",
      "drwxr-xr-x  7 lmoresi  staff        224 29 Mar  2017 HYP_50M_SR_W\n",
      "-rw-r--r--  1 lmoresi  staff  102197989 29 Mar  2017 HYP_50M_SR_W.zip\n",
      "drwxr-xr-x  7 lmoresi  staff        224 29 Mar  2017 OB_50M\n",
      "-rw-r--r--  1 lmoresi  staff   50471544 29 Mar  2017 OB_50M.zip\n",
      "-rw-r--r--  1 lmoresi  staff     675266 29 Mar  2017 OrthographicProjectionBlueMarble.png\n",
      "-rw-r--r--  1 lmoresi  staff        214 29 Mar  2017 README.md\n",
      "-rw-r--r--  1 lmoresi  staff   43762944 29 Mar  2017 color_etopo1_ice_low.tif\n",
      "-rw-r--r--  1 lmoresi  staff   35751844 29 Mar  2017 color_etopo1_ice_low.tif.zip\n",
      "-rw-r--r--  1 lmoresi  staff  116624719 29 Mar  2017 etopo1_grayscale_hillshade.tif\n",
      "-rw-r--r--  1 lmoresi  staff  115038692 29 Mar  2017 etopo1_grayscale_hillshade.tif.zip\n",
      "-rw-r--r--  1 lmoresi  staff  116407016 29 Mar  2017 global_age_data.3.6.xyz\n",
      "-rw-r--r--@ 1 lmoresi  staff   33316312 29 Mar  2017 global_age_data.3.6.xyz.zip\n",
      "-rw-r--r--  1 lmoresi  staff   21987373 29 Mar  2017 global_age_data.3.6.z.npz\n",
      "-rwxr-xr-x  1 lmoresi  staff       2183 29 Mar  2017 nb_stripper.py\n",
      "-rw-r--r--  1 lmoresi  staff   34678800 29 Mar  2017 sec_invariant_strain_0.2.dat\n",
      "-rw-r--r--  1 lmoresi  staff    4309416 29 Mar  2017 sec_invariant_strain_0.2.dat.zip\n",
      "-rw-r--r--  1 lmoresi  staff     466364 29 Mar  2017 velocity_AU.nc\n",
      "-rw-r--r--  1 lmoresi  staff     466364 29 Mar  2017 velocity_EU.nc\n",
      "-rw-r--r--  1 lmoresi  staff     466364 29 Mar  2017 velocity_IN.nc\n",
      "-rw-r--r--  1 lmoresi  staff     466364 29 Mar  2017 velocity_NA.nc\n",
      "-rw-r--r--  1 lmoresi  staff     466364 29 Mar  2017 velocity_NNR.nc\n",
      "-rw-r--r--  1 lmoresi  staff     466364 29 Mar  2017 velocity_OK.nc\n",
      "-rw-r--r--  1 lmoresi  staff     466324 29 Mar  2017 velocity_PA.nc\n",
      "-rw-r--r--  1 lmoresi  staff     466364 29 Mar  2017 velocity_TA.nc\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "ls -l ../../Data/Reference/\n",
    "ls -l ../../Data/Resources/\n",
    "\n",
    "cp ../../Data/Reference/* ../../Data/Resources/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "shown",
    "solution_first": true
   },
   "source": [
    "## The datasets that we use for this course are kept in a central location. \n",
    "\n",
    "These can be downloaded on demand but the smaller files are stored away in the `Reference` directory and copied to the `Resources` directory. \n",
    "\n",
    "   - Why do I do that ? \n",
    "\n",
    "So if you happen to delete or break one of the datasets, we can get a new copy. __Expand the cell__ to see the details of the download and caching mechanism. \n",
    "\n",
    "   - `md5` checksums\n",
    "   - the `requests` module for handling urls (properly)\n",
    "   - exception handling (!)\n",
    "\n",
    "``` python\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "def download_file(url, local_filename, expected_size):\n",
    "    \n",
    "    if (os.path.isfile(url)):\n",
    "        shutil.copy(url, local_filename)\n",
    "        \n",
    "# and so on ...         \n",
    "``` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": false,
    "solution": "shown"
   },
   "outputs": [],
   "source": [
    "## Here are some functions to download or install files. \n",
    "\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "def download_file(url, local_filename, expected_size):\n",
    "    \n",
    "    \n",
    "# We might want to bundle some files if they are small / compressed or not readily available for download\n",
    "\n",
    "    if (os.path.isfile(url)):\n",
    "        shutil.copy(url, local_filename)\n",
    "    \n",
    "    else:\n",
    "        r = requests.get(url, stream=True)\n",
    "\n",
    "        start_time = time.time()\n",
    "        last_time = start_time\n",
    "        datasize = 0\n",
    "\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=10000000): \n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "                    f.flush()\n",
    "                    datasize += len(chunk)\n",
    "                    if (time.time() - last_time) > 2.5:\n",
    "                        print (\"{:.1f} Mb in {:.1f}s / {}\".format(datasize / 1.0e6, time.time() - start_time, expected_size))\n",
    "                        last_time = time.time()\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "solution": "shown"
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from functools import partial\n",
    "\n",
    "def md5sum(filename):\n",
    "    with open(filename, mode='rb') as f:\n",
    "        d = hashlib.md5()\n",
    "        for buf in iter(partial(f.read, 4096), b''):\n",
    "            d.update(buf)\n",
    "    return d.hexdigest()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def download_cached_file(location_url, local_file, expected_md5, expected_size=\"Unknown\"):\n",
    "\n",
    "    try:\n",
    "        assert md5sum(local_file) == expected_md5\n",
    "        print (\"Using cached file - {}\".format(local_file))\n",
    "        return(2)\n",
    "    \n",
    "    except (IOError, AssertionError) as error_info:\n",
    "        # No file or the wrong file ... best go download it\n",
    "        # print \"Assertion failed - {}\".format(sys.exc_info())\n",
    "        \n",
    "        try:\n",
    "            data_file = download_file(location_url, local_file, expected_size)\n",
    "            print (\"Downloaded from {}\".format( location_url ))\n",
    "            return(1)\n",
    "\n",
    "        except:\n",
    "            print (\"Unable to download {} [{}] \".format( location_url, sys.exc_info() ))\n",
    "            return(0)\n",
    "\n",
    "\n",
    "def report_cached_file(local_file, expected_md5):\n",
    "    \n",
    "    import os.path\n",
    "    \n",
    "    if not os.path.isfile(local_file):\n",
    "        print (\"Local file {} does not exist\".format(local_file))\n",
    "    else:\n",
    "        if len(expected_md5) == 0 or md5sum(local_file) == expected_md5:\n",
    "            print (\"Cached file {} is valid\".format(local_file))\n",
    "        else:\n",
    "            print (\"Cached file {} failed, checksum {}\".format(local_file, md5sum(local_file)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "## The resources \"database\"\n",
    "\n",
    "The files are managed by keeping a table of the download point and a checksum to validate the file.\n",
    "\n",
    "Although it is a little laborious to set this up, it is a useful way to keep track of the data sources. For very large collections, you would probably do better with a database not a hand-built dictionary\n",
    "\n",
    "The database takes the form of a dictionary like this:\n",
    "\n",
    "```python\n",
    "\n",
    "resource_list = [\n",
    "# Global magnetic data \n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/EMAG2_image_V2.tif\",\n",
    " \"md5\":\"c4944c27ed22ddc89225e506936b016b\",\n",
    " \"url\":\"http://geomag.org/models/EMAG2/EMAG2_image_V2.tif\",\n",
    " \"expected_size\":\"133Mb\"\n",
    "},\n",
    "\n",
    "# and so on ... \n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hide_input": false,
    "solution": "hidden"
   },
   "outputs": [],
   "source": [
    "# ../../Data/Resources required for the tutorial\n",
    "# The checksum is to make sure any cached file is the right one.\n",
    "# If the checksum is wrong the file gets downloaded again.\n",
    "\n",
    "# Some of these files are local, stored in the repo in compressed form and installed into the\n",
    "# ../../Data/Resources directory. \n",
    "\n",
    "resource_list = [\n",
    "# Global magnetic data \n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/EMAG2_image_V2.tif\",\n",
    " \"md5\":\"c4944c27ed22ddc89225e506936b016b\",\n",
    " \"url\":\"http://geomag.org/models/EMAG2/EMAG2_image_V2.tif\",\n",
    " \"expected_size\":\"133Mb\"\n",
    "},\n",
    "    \n",
    "# Australian Mag Data from AuScope portal (built by hand)\n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/AusMagAll.tiff.zip\",\n",
    " \"md5\":'',\n",
    " \"url\":\"../../Data/Reference/AusMagAll.tiff.zip\",\n",
    " \"expected_size\":\"10Mb\"\n",
    "},\n",
    "    \n",
    "# Blue Marble Image Geotiff June 2004 (11Mb)  \n",
    "{\n",
    " \"local_file\": \"../../Data/Resources/BlueMarbleNG-TB_2004-06-01_rgb_3600x1800.TIFF\",\n",
    " \"md5\": '55e1399674d43a26353d84c114d7ff80',\n",
    " \"url\":\"http://neo.sci.gsfc.nasa.gov/servlet/RenderData?si=526294&cs=rgb&format=TIFF&width=3600&height=1800\",\n",
    " \"expected_size\":\"11Mb\"\n",
    "},\n",
    "    \n",
    "    \n",
    "# Blue Marble Image with Bathymetry png - December 2004 \n",
    "{\n",
    " \"local_file\": \"../../Data/Resources/BlueMarbleNG-TB_2004-12-01_rgb_3600x1800.TIFF\",\n",
    " \"md5\": '825da4b417ae19e24d2ea6db6cf8ad21',\n",
    " \"url\":\"http://neo.sci.gsfc.nasa.gov/servlet/RenderData?si=526311&cs=rgb&format=TIFF&width=3600&height=1800\",\n",
    " \"expected_size\":\"11Mb\"\n",
    "},\n",
    "    \n",
    "# Etopo1 - color image \n",
    "{\n",
    " \"local_file\": \"../../Data/Resources/color_etopo1_ice_low.tif.zip\",\n",
    " \"md5\": '3f53d72e85393deb28874db0c76fbfcb',\n",
    " \"url\":\"https://www.ngdc.noaa.gov/mgg/global/relief/ETOPO1/image/color_etopo1_ice_low.tif.zip\",\n",
    " \"expected_size\":\"35Mb\"\n",
    "},\n",
    "    \n",
    "# Etopo1 - bw shaded relief image \n",
    "{\n",
    " \"local_file\": \"../../Data/Resources/etopo1_grayscale_hillshade.tif.zip\",\n",
    " \"md5\": 'f38b8dc6cd971d72e77edaa837d5b85c',\n",
    " \"url\":\"https://www.ngdc.noaa.gov/mgg/global/relief/ETOPO1/image/etopo1_grayscale_hillshade.tif.zip\",\n",
    " \"expected_size\":\"115Mb\"\n",
    "},\n",
    "    \n",
    "    \n",
    "# ETOPO_c_geotiff_10800 ... cell centred data for ETOPO1 \n",
    "{\n",
    " \"local_file\": \"../../Data/Resources/ETOPO_c_geotiff_10800.tif.zip\",\n",
    " \"md5\":\"fbd0478d0974ca433cdd5cb3530d0d48\",\n",
    " \"url\":\"https://www.ngdc.noaa.gov/mgg/global/relief/ETOPO1/data/ice_surface/cell_registered/georeferenced_tiff/ETOPO1_Ice_c_geotiff.zip\",\n",
    " \"expected_size\":\"320Mb\"\n",
    "},    \n",
    "    \n",
    "# Natural Earth Hypsometry Images (same grid size as ETOPO1 image above)\n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/HYP_50M_SR_W.zip\",\n",
    " \"md5\":\"f3323bc6f38ddec98cff4936fb324ec5\",\n",
    " \"url\":\"http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/50m/raster/HYP_50M_SR_W.zip\",\n",
    " \"expected_size\":\"102Mb\"\n",
    "},   \n",
    " \n",
    "# Natural Earth Ocean Bottom Images (same grid size as ETOPO1 image above)\n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/OB_50M.zip\",\n",
    " \"md5\":\"69a2ed6ff8cf30b2dedd2d80461f9e43\",\n",
    " \"url\":\"http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/50m/raster/OB_50M.zip\",\n",
    " \"expected_size\":\"50Mb\"\n",
    "},   \n",
    "            \n",
    "# Global age grid  [LOCAL]\n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/global_age_data.3.6.z.npz\",\n",
    " \"md5\":'',\n",
    " \"url\":\"../../Data/Reference/global_age_data.3.6.z.npz\",\n",
    " \"expected_size\":\"22Mb\"\n",
    "},\n",
    " \n",
    "# Global age grid (raw) [LOCAL]\n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/global_age_data.3.6.xyz.zip\",\n",
    " \"md5\":'',\n",
    " \"url\":\"../../Data/Reference/global_age_data.3.6.xyz\",\n",
    " \"expected_size\":\"22Mb\"\n",
    "},\n",
    "\n",
    "\n",
    "# Global second invariant of strain rate [LOCAL]\n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/sec_invariant_strain_0.2.dat.zip\",\n",
    " \"md5\":'',\n",
    " \"url\":\"../../Data/Reference/sec_invariant_strain_0.2.dat.zip\",\n",
    " \"expected_size\":\"4Mb\"\n",
    "},\n",
    "  \n",
    "    \n",
    "# Earthquake data for various regions as json files [LOCAL]\n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/Earthquake_data.zip\",\n",
    " \"md5\":'',\n",
    " \"url\":\"../../Data/Reference/Earthquake_data.zip\",\n",
    " \"expected_size\":\"4Mb\"\n",
    "},\n",
    "    \n",
    "    \n",
    "# Global surface velocity vector fields in various reference frames:\n",
    "# http://gsrm.unavco.org/model/\n",
    "# There are others ... \n",
    "    \n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/velocity_AU.nc\",\n",
    " \"md5\":'',\n",
    " \"url\":\"../../Data/Reference/velocity_AU.nc\",\n",
    " \"expected_size\":\"1Mb\"\n",
    "},   \n",
    "  \n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/velocity_EU.nc\",\n",
    " \"md5\":'',\n",
    " \"url\":\"../../Data/Reference/velocity_EU.nc\",\n",
    " \"expected_size\":\"1Mb\"\n",
    "},   \n",
    "\n",
    "\n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/velocity_IN.nc\",\n",
    " \"md5\":'',\n",
    " \"url\":\"../../Data/Reference/velocity_IN.nc\",\n",
    " \"expected_size\":\"1Mb\"\n",
    "},   \n",
    "\n",
    "\n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/velocity_NA.nc\",\n",
    " \"md5\":'',\n",
    " \"url\":\"../../Data/Reference/velocity_NA.nc\",\n",
    " \"expected_size\":\"1Mb\"\n",
    "},   \n",
    "\n",
    "\n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/velocity_OK.nc\",\n",
    " \"md5\":'',\n",
    " \"url\":\"../../Data/Reference/velocity_OK.nc\",\n",
    " \"expected_size\":\"1Mb\"\n",
    "},   \n",
    "\n",
    "\n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/velocity_NNR.nc\",\n",
    " \"md5\":'',\n",
    " \"url\":\"../../Data/Reference/velocity_NNR.nc\",\n",
    " \"expected_size\":\"1Mb\"\n",
    "},   \n",
    "\n",
    "\n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/velocity_PA.nc\",\n",
    " \"md5\":'',\n",
    " \"url\":\"../../Data/Reference/velocity_PA.nc\",\n",
    " \"expected_size\":\"1Mb\"\n",
    "},   \n",
    "\n",
    "\n",
    "{\n",
    " \"local_file\":\"../../Data/Resources/velocity_TA.nc\",\n",
    " \"md5\":'',\n",
    " \"url\":\"../../Data/Reference/velocity_TA.nc\",\n",
    " \"expected_size\":\"1Mb\"\n",
    "},   \n",
    "\n",
    "       \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking ../../Data/Resources/EMAG2_image_V2.tif (c4944c27ed22ddc89225e506936b016b)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-57b25a7813e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresource\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresource_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nChecking {:s} ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"local_file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"md5\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mreport_cached_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"local_file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"md5\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-4fbbbcc60378>\u001b[0m in \u001b[0;36mreport_cached_file\u001b[0;34m(local_file, expected_md5)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Local file {} does not exist\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_md5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmd5sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected_md5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Cached file {} is valid\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4fbbbcc60378>\u001b[0m in \u001b[0;36mmd5sum\u001b[0;34m(filename, blocksize)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mhash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for resource in resource_list:\n",
    "    print (\"\\nChecking {:s} ({})\".format(resource[\"local_file\"], resource[\"md5\"]))\n",
    "    report_cached_file(resource[\"local_file\"],resource[\"md5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "607896ac3ad90ef8d544f0c1c32d63ef\n"
     ]
    }
   ],
   "source": [
    "# md5sum(\"../../Data/Resources/EMAG2_image_V2.tif\")\n",
    "  \n",
    "\n",
    "filename=\"Readme.md\"\n",
    "\n",
    "import hashlib \n",
    "from functools import partial\n",
    "\n",
    "def md5sum(filename):\n",
    "    with open(filename, mode='rb') as f:\n",
    "        d = hashlib.md5()\n",
    "        for buf in iter(partial(f.read, 4096), b''):\n",
    "            d.update(buf)\n",
    "    return d.hexdigest()\n",
    "\n",
    "print(md5sum(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for resource in resource_list:\n",
    "    print (\"\\nDownloading {:s}\".format(resource[\"local_file\"]))\n",
    "    download_cached_file(resource[\"url\"], resource[\"local_file\"], resource[\"md5\"], resource[\"expected_size\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract any files that were downloaded as zip archives (keep the originals to avoid re-downloading)\n",
    "\n",
    "import zipfile\n",
    "import glob\n",
    "\n",
    "for zipped in glob.glob(\"../../Data/Resources/*.zip\"):\n",
    "    with zipfile.ZipFile(zipped) as zf:\n",
    "        zf.extractall(\"../../Data/Resources\")\n",
    "        print (\"Unzipped {}\".format(zipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you add a new url / file to the download list above, add the md5 checksum as well !\n",
    "# unless it is small enough to have a local copy. I would suggest still providing a url\n",
    "# in the comments just in case.\n",
    "\n",
    "md5sum(\"../../Data/Resources/etopo1_grayscale_hillshade.tif.zip\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
